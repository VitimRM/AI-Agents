{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796917ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 1: Importações e Configuração da Chave da API OpenAI\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import asyncio # Necessário para executar funções assíncronas\n",
    "import PyPDF2 # Para a ferramenta de PDF, se você quiser mantê-la\n",
    "from bs4 import BeautifulSoup # Para a ferramenta de URL, se você quiser mantê-la\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# --- 1. Configuração da Chave da API OpenAI ---\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"AVISO: A variável de ambiente OPENAI_API_KEY não está definida.\")\n",
    "    print(\"Por favor, defina-a para que o agente possa se comunicar com a OpenAI.\")\n",
    "    # Exemplo (NÃO RECOMENDADO PARA PRODUÇÃO):\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"sk-...\" # SUBSTITUA PELA SUA CHAVE REAL!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7528d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_from_txt(chapter_identifier_and_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Atua como um monitor de Eletromagnetismo, buscando informações em um capítulo específico\n",
    "    lendo o conteúdo de um arquivo TXT local e respondendo a uma pergunta com base nesse conteúdo.\n",
    "\n",
    "    A entrada deve ser uma string no formato 'IDENTIFICADOR_DO_CAPITULO|SUA_PERGUNTA'.\n",
    "    O IDENTIFICADOR_DO_CAPITULO será usado para formar o nome do arquivo (ex: 'Capitulo 2' -> 'Capitulo 2.txt').\n",
    "    Este arquivo TXT deve estar na mesma pasta que o script.\n",
    "\n",
    "    Args:\n",
    "        chapter_identifier_and_query (str): Uma string contendo o identificador do capítulo\n",
    "                                            e a pergunta do aluno, separados por '|'.\n",
    "\n",
    "    Returns:\n",
    "        str: A resposta do LLM baseada no conteúdo do capítulo ou uma mensagem de erro.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Divide a string de entrada em identificador do capítulo e pergunta\n",
    "        parts = chapter_identifier_and_query.split('|', 1)\n",
    "        if len(parts) != 2:\n",
    "            return \"Erro: Formato de entrada inválido. Use 'IDENTIFICADOR_DO_CAPITULO|SUA_PERGUNTA'.\"\n",
    "\n",
    "        chapter_identifier = parts[0].strip()\n",
    "        student_question = parts[1].strip()\n",
    "\n",
    "        if not chapter_identifier or not student_question:\n",
    "            return \"Erro: Identificador do capítulo ou pergunta não fornecida.\"\n",
    "\n",
    "        # Constrói o nome do arquivo esperado (ex: \"Capitulo 2.txt\")\n",
    "        file_name = f\"{chapter_identifier}.txt\"\n",
    "        # Caminho completo para o arquivo (assumindo que está na mesma pasta do script)\n",
    "        file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            return f\"Erro: Arquivo '{file_name}' não encontrado na pasta atual. Certifique-se de que o arquivo está na mesma pasta que o script.\"\n",
    "\n",
    "        chapter_content = \"\"\n",
    "        try:\n",
    "            # Tenta ler o arquivo com codificação UTF-8. Se falhar, tenta latin-1.\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                chapter_content = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                    chapter_content = file.read()\n",
    "            except Exception as e:\n",
    "                return f\"Erro de decodificação ao ler o arquivo '{file_name}': {e}\"\n",
    "        except Exception as e:\n",
    "            return f\"Erro ao ler o arquivo '{file_name}': {e}\"\n",
    "\n",
    "        if not chapter_content.strip():\n",
    "            return f\"Erro: O arquivo '{file_name}' está vazio ou não contém texto legível.\"\n",
    "\n",
    "        # Limita o tamanho do texto do capítulo para evitar exceder o limite de tokens do LLM\n",
    "        max_content_length = 25000 # Ajuste conforme o limite do seu uso e do modelo\n",
    "        if len(chapter_content) > max_content_length:\n",
    "            chapter_content = chapter_content[:max_content_length] + \"\\n[CONTEÚDO TRUNCADO]\"\n",
    "            # print(f\"Aviso: Conteúdo do capítulo '{chapter_identifier}' truncado para {max_content_length} caracteres.\") # Comentado para não poluir o output\n",
    "\n",
    "        # Constrói o prompt para o modelo de linguagem\n",
    "        prompt_text = (\n",
    "            f\"Você é um monitor de Eletromagnetismo. Um aluno perguntou sobre o capítulo '{chapter_identifier}'. \"\n",
    "            f\"Aqui está o conteúdo do capítulo para referência:\\n\\n\"\n",
    "            f\"```chapter_content\\n{chapter_content}\\n```\\n\\n\"\n",
    "            f\"Com base APENAS neste conteúdo do capítulo, responda à seguinte pergunta do aluno: \\\"{student_question}\\\"\\n\"\n",
    "            f\"Se a resposta não estiver explicitamente no texto fornecido, diga que a informação não está disponível no capítulo ou que você não pode responder com base nele.\"\n",
    "        )\n",
    "\n",
    "        # Inicializa o modelo de linguagem (GPT-4o Mini, conforme sua preferência)\n",
    "        # Temperatura mais baixa (0.2) para respostas mais factuais e menos criativas.\n",
    "        llm_openai = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "        # Prepara o payload para a API da OpenAI (formato 'messages')\n",
    "        chat_history = [{ \"role\": \"user\", \"content\": prompt_text }] # OpenAI API usa 'content'\n",
    "        payload = { \"model\": \"gpt-4o-mini\", \"messages\": chat_history, \"temperature\": 0.2 }\n",
    "\n",
    "        apiKey = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not apiKey:\n",
    "            return \"Erro: Chave da API da OpenAI não configurada. Por favor, defina a variável de ambiente OPENAI_API_KEY.\"\n",
    "\n",
    "        apiUrl = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {apiKey}'\n",
    "        }\n",
    "\n",
    "        response = requests.post(apiUrl, headers=headers, data=json.dumps(payload))\n",
    "        response.raise_for_status() # Lança exceções para status de erro HTTP (4xx ou 5xx)\n",
    "\n",
    "        result = response.json()\n",
    "\n",
    "        # Verifica e retorna a resposta do LLM\n",
    "        if result.get(\"choices\") and len(result[\"choices\"]) > 0 and \\\n",
    "           result[\"choices\"][0].get(\"message\") and \\\n",
    "           result[\"choices\"][0][\"message\"].get(\"content\"):\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            return \"Não foi possível obter uma resposta do monitor para esta pergunta.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Erro ao acessar a API da OpenAI: {e}. Verifique sua conexão, quota ou chave da API.\"\n",
    "    except Exception as e:\n",
    "        return f\"Ocorreu um erro inesperado ao consultar o capítulo: {e}\"\n",
    "\n",
    "# Criação da Ferramenta LangChain\n",
    "monitor_tool = Tool(\n",
    "    name=\"lookup_txt\",\n",
    "    func=lookup_from_txt,\n",
    "    description=(\n",
    "        \"Útil para consultar informações em um capítulo específico do material de Eletromagnetismo. \"\n",
    "        \"A entrada deve ser o IDENTIFICADOR EXATO DO CAPÍTULO (ex: 'Capitulo 2') seguido de '|' e, em seguida, a PERGUNTA do aluno. \"\n",
    "        \"O agente tentará ler o arquivo TXT correspondente (ex: 'Capitulo 2.txt') na mesma pasta do script.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aed9152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Você: Capitulo 1, O que é o eletromagnetismo?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: lookup_txt  \n",
      "Action Input: \"Capitulo 1|O que é o eletromagnetismo?\"  \u001b[0m\u001b[36;1m\u001b[1;3mO eletromagnetismo é o ramo da física que estuda a interação entre campos elétricos e magnéticos.\u001b[0m\u001b[32;1m\u001b[1;3mThought: Eu sei a resposta final.\n",
      "Final Answer: O eletromagnetismo é o ramo da física que estuda a interação entre campos elétricos e magnéticos.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta do Agente ---\n",
      "Moriarty: O eletromagnetismo é o ramo da física que estuda a interação entre campos elétricos e magnéticos.\n",
      "\n",
      "Agente encerrado.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Inicialização do Modelo de Linguagem (LLM Principal do Agente) ---\n",
    "# Este é o LLM que o agente usa para raciocinar e gerar respostas gerais.\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# --- 4. Preparação do Agente ---\n",
    "# Define as ferramentas que o agente pode usar\n",
    "# Mantenha apenas as ferramentas que você deseja no seu agente Moriarty.\n",
    "# Se quiser apenas o monitor de eletromagnetismo, mantenha apenas ele.\n",
    "tools = [\n",
    "    monitor_tool # A ferramenta principal para este exemplo\n",
    "]\n",
    "\n",
    "# Personalizando o Prompt do Agente para guiar seu comportamento\n",
    "custom_prompt_template = \"\"\"\n",
    "Você é um assistente de IA útil e inteligente.\n",
    "Seu nome é James Moriarty.\n",
    "Sua principal função é atuar como um monitor de Eletromagnetismo.\n",
    "PRIMEIRO, tente responder diretamente usando seu próprio conhecimento.\n",
    "SEGUNDO, se a pergunta do aluno for sobre um capítulo específico da matéria, use a ferramenta 'lookup_electromagnetism_chapter' para consultar o arquivo TXT correspondente.\n",
    "Use a ferramenta APENAS quando for estritamente necessário e a pergunta se referir a um capítulo específico.\n",
    "\n",
    "Aqui estão as ferramentas que você pode usar:\n",
    "{tools}\n",
    "\n",
    "Use o seguinte formato:\n",
    "\n",
    "Question: a pergunta de entrada que você deve responder\n",
    "Thought: você deve sempre pensar sobre o que fazer.\n",
    "Action: a ação a ser tomada, deve ser uma das [{tool_names}]\n",
    "Action Input: a entrada para a ação (NÃO use aspas duplas aqui)\n",
    "Observation: o resultado da ação\n",
    "... (este Thought/Action/Action Input/Observation pode se repetir N vezes)\n",
    "Thought: Eu sei a resposta final\n",
    "Final Answer: a resposta final à pergunta original\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Crie um novo PromptTemplate com suas instruções personalizadas\n",
    "prompt = PromptTemplate.from_template(custom_prompt_template)\n",
    "prompt = prompt.partial(\n",
    "    tools=str(tools),\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "# Cria o agente\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Cria o executor do agente\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# --- 5. Execução do Agente (Loop de Chat Assíncrono para Jupyter) ---\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"\\nSua pergunta (ou 'sair' para terminar): \")\n",
    "        if user_input.lower() == 'sair':\n",
    "            break\n",
    "\n",
    "        print(f\"\\nVocê: {user_input}\")\n",
    "        response = agent_executor.invoke({\"input\": user_input})\n",
    "        print(\"\\n--- Resposta do Agente ---\")\n",
    "        print('Moriarty:', response[\"output\"])\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro: {e}\")\n",
    "        print(\"Tente novamente ou verifique se sua chave da OpenAI está configurada corretamente.\")\n",
    "\n",
    "print(\"\\nAgente encerrado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
