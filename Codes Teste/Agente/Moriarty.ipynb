{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6b3f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# Se você não definir a variável de ambiente, pode descomentar a linha abaixo e colocar sua chave diretamente:\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"AVISO: A variável de ambiente OPENAI_API_KEY não está definida.\")\n",
    "    print(\"Por favor, defina-a ou insira sua chave diretamente no código.\")\n",
    "    # Exemplo (NÃO RECOMENDADO PARA PRODUÇÃO):\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"sk-...\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c048349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Função que o agente usará para 'extrair' informações de um link ---\n",
    "def get_text_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai todo o texto visível de uma URL fornecida.\n",
    "    Útil para ler o conteúdo de páginas web.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10) # Adiciona um timeout para evitar esperas infinitas\n",
    "        response.raise_for_status()  # Lança um erro para códigos de status HTTP ruins (4xx ou 5xx)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Remove elementos de script e estilo\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "\n",
    "        # Obtém o texto\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Quebra linhas em espaços e remove espaços em branco extras\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "        # Limita o tamanho do texto para evitar sobrecarga do LLM\n",
    "        max_length = 4000 # Limite de caracteres para o texto extraído\n",
    "        if len(text) > max_length:\n",
    "            print(f\"ATENÇÃO: Texto da URL truncado de {len(text)} para {max_length} caracteres.\")\n",
    "            text = text[:max_length] + \"...\" # Adiciona reticências para indicar truncamento\n",
    "\n",
    "        return text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Erro ao acessar a URL: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao processar o conteúdo da URL: {e}\"\n",
    "\n",
    "# Cria a ferramenta para extrair texto de URL\n",
    "url_text_extractor_tool = Tool(\n",
    "    name=\"get_text_from_url\",\n",
    "    func=get_text_from_url,\n",
    "    description=\"Útil para extrair o conteúdo de texto de uma página web a partir de uma URL. Forneça uma URL completa como entrada.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d8e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Função que o agente usará para 'extrair' informações de vídeo ---\n",
    "async def get_youtube_info(url_and_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Simula a extração de informações de um vídeo do YouTube usando um LLM.\n",
    "    Recebe uma string no formato 'URL_DO_VIDEO|SUA_PERGUNTA'.\n",
    "    Ex: 'https://www.youtube.com/watch?v=dQw4w9WgXcQ| Qual é o tema principal?'\n",
    "\n",
    "    Esta função não assiste ao vídeo. Ela usa a inteligência do LLM\n",
    "    para inferir ou resumir informações com base no seu conhecimento pré-existente\n",
    "    e no contexto fornecido (URL e pergunta).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Divide a string de entrada em URL e pergunta\n",
    "        parts = url_and_query.split('|', 1)\n",
    "        if len(parts) != 2:\n",
    "            return \"Erro: Formato de entrada inválido. Use 'URL_DO_VIDEO|SUA_PERGUNTA'.\"\n",
    "\n",
    "        youtube_url = parts[0].strip()\n",
    "        user_query = parts[1].strip()\n",
    "\n",
    "        if not youtube_url or not user_query:\n",
    "            return \"Erro: URL do vídeo ou pergunta não fornecida.\"\n",
    "\n",
    "        # Constrói o prompt para o modelo de linguagem\n",
    "        prompt_text = f\"Dado o seguinte URL de vídeo do YouTube: {youtube_url}\\n\\nResponda à seguinte pergunta, imaginando o conteúdo do vídeo ou resumindo-o se você tiver informações contextuais sobre ele: \\\"{user_query}\\\"\\n\\nSe você não souber, diga que não sabe com base no contexto fornecido.\"\n",
    "\n",
    "        # Prepara o histórico de chat para a requisição da API\n",
    "        chat_history = [{ \"role\": \"user\", \"parts\": [{ \"text\": prompt_text }] }]\n",
    "\n",
    "        # Payload da requisição para a API do Gemini\n",
    "        payload = { \"contents\": chat_history }\n",
    "\n",
    "        # A chave da API será fornecida automaticamente pelo ambiente Canvas se deixada vazia\n",
    "        apiKey = \"\"\n",
    "        apiUrl = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={apiKey}\"\n",
    "\n",
    "        # Realiza a requisição fetch para a API do Google Gemini\n",
    "        # Nota: requests.post é usado aqui para compatibilidade em ambientes Python síncronos\n",
    "        # No ambiente Canvas, `fetch` é um método global disponível no escopo do navegador para React/HTML\n",
    "        # Para Python puro rodando em um servidor ou ambiente de script, você usaria `requests`\n",
    "        # Aqui, estamos simulando a chamada fetch com requests, que é o que você usaria em um ambiente de servidor Python\n",
    "        response = requests.post(apiUrl, headers={'Content-Type': 'application/json'}, data=json.dumps(payload))\n",
    "        response.raise_for_status() # Lança exceções para status de erro HTTP (4xx ou 5xx)\n",
    "\n",
    "        result = response.json()\n",
    "\n",
    "        # Verifica se a resposta contém o texto esperado\n",
    "        if result.get(\"candidates\") and len(result[\"candidates\"]) > 0 and \\\n",
    "           result[\"candidates\"][0].get(\"content\") and \\\n",
    "           result[\"candidates\"][0][\"content\"].get(\"parts\") and \\\n",
    "           len(result[\"candidates\"][0][\"content\"][\"parts\"]) > 0:\n",
    "            return result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        else:\n",
    "            return \"Não foi possível obter uma resposta do LLM para esta pergunta.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Erro ao acessar a API da OpenAI/Google Gemini: {e}. Verifique sua conexão ou quota.\"\n",
    "    except Exception as e:\n",
    "        return f\"Ocorreu um erro inesperado ao processar a requisição: {e}\"\n",
    "\n",
    "# --- 2. Criação da Ferramenta LangChain ---\n",
    "# Esta é a ferramenta que você adicionará à lista de ferramentas do seu agente.\n",
    "youtube_info_extractor_tool = Tool(\n",
    "    name=\"get_youtube_info\",\n",
    "    func=get_youtube_info, # Assumindo que o agente pode chamar funções assíncronas\n",
    "    description=\"Útil para obter informações sobre um vídeo do YouTube. A entrada deve ser no formato 'URL_DO_VIDEO|SUA_PERGUNTA', por exemplo, 'https://www.youtube.com/watch?v=dQw4w9WgXcQ|Qual é o tema principal deste vídeo?'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b20a65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def extract_text_from_pdf(pdf_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Extrai todo o texto de um arquivo PDF.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"Erro: Arquivo não encontrado em {pdf_path}\")\n",
    "        return None\n",
    "\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao ler o PDF: {e}\")\n",
    "        return None\n",
    "extract_text_from_pdf_tool = Tool(\n",
    "    name=\"extract_text_from_pdf\",\n",
    "    func=extract_text_from_pdf, # Assumindo que o agente pode chamar funções assíncronas\n",
    "    description=\"Útil para obter informações sobre um vídeo do YouTube. A entrada deve ser no formato 'URL_DO_VIDEO|SUA_PERGUNTA', por exemplo, 'https://www.youtube.com/watch?v=dQw4w9WgXcQ|Qual é o tema principal deste vídeo?'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef84eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Você: Qual seu nome\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: A pergunta é direta e simples, e já está respondida no próprio enunciado inicial, onde foi informado que meu nome é James Moriarty.\n",
      "Final Answer: Meu nome é James Moriarty.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Resposta do Agente ---\n",
      "Professor M.: Meu nome é James Moriarty.\n",
      "\n",
      "Agente encerrado.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Inicialização do Modelo de Linguagem (LLM) ---\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.7)\n",
    "\n",
    "# --- 4. Preparação do Agente ---\n",
    "# Define as ferramentas que o agente pode usar\n",
    "tools = [\n",
    "    url_text_extractor_tool,\n",
    "    youtube_info_extractor_tool,\n",
    "    extract_text_from_pdf_tool\n",
    "    ]\n",
    "\n",
    "\n",
    "# Criar um novo PromptTemplate ou modificar o template do base_prompt\n",
    "# Exemplo de um template mais explícito:\n",
    "custom_prompt_template = \"\"\"\n",
    "Você é um assistente de IA útil e inteligente.\n",
    "Seu nome é James Moriarty.\n",
    "Sua principal função é responder às perguntas do usuário.\n",
    "PRIMEIRO, tente responder diretamente usando seu próprio conhecimento.\n",
    "SEGUNDO, se você não souber a resposta, ou se a pergunta exigir informações muito específicas, atualizadas, ou a análise de um documento/URL, então use as ferramentas disponíveis.\n",
    "Use as ferramentas APENAS quando for estritamente necessário para obter informações que você não possui.\n",
    "\n",
    "Aqui estão as ferramentas que você pode usar:\n",
    "{tools}\n",
    "\n",
    "Use o seguinte formato:\n",
    "\n",
    "Question: a pergunta de entrada que você deve responder\n",
    "Thought: você deve sempre pensar sobre o que fazer.\n",
    "Action: a ação a ser tomada, deve ser uma das [{tool_names}]\n",
    "Action Input: a entrada para a ação (NÃO use aspas duplas aqui)\n",
    "Observation: o resultado da ação\n",
    "... (este Thought/Action/Action Input/Observation pode se repetir N vezes)\n",
    "Thought: Eu sei a resposta final\n",
    "Final Answer: a resposta final à pergunta original\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Crie um novo PromptTemplate com suas instruções personalizadas\n",
    "# Certifique-se de que as variáveis de entrada (input_variables) correspondem ao que o create_react_agent espera.\n",
    "prompt = PromptTemplate.from_template(custom_prompt_template)\n",
    "prompt = prompt.partial(\n",
    "    tools=str(tools), # Ferramentas precisam ser passadas como string para o template\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "# Cria o agente\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Cria o executor do agente\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# --- 5. Execução do Agente ---\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"\\nSua pergunta (ou 'sair' para terminar): \")\n",
    "        if user_input.lower() == 'sair':\n",
    "            break\n",
    "\n",
    "        print(f\"\\nVocê: {user_input}\")\n",
    "        response = agent_executor.invoke({\"input\": user_input})\n",
    "        print(\"\\n--- Resposta do Agente ---\")\n",
    "        print('Moriarty:', response[\"output\"])\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro: {e}\")\n",
    "        print(\"Tente novamente ou verifique se sua chave da OpenAI está configurada corretamente.\")\n",
    "\n",
    "print(\"\\nAgente encerrado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
