{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ec0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import PyPDF2\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import json # Adicione esta importação se ainda não a tiver para a ferramenta de YouTube/PDF\n",
    "import asyncio\n",
    "\n",
    "# --- 1. Configuração da Chave da API OpenAI ---\n",
    "# Certifique-se de que sua chave da API da OpenAI esteja configurada como uma variável de ambiente\n",
    "# ou substitua \"YOUR_OPENAI_API_KEY\" pela sua chave real.\n",
    "# É altamente recomendável usar variáveis de ambiente por segurança:\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# Se você não definir a variável de ambiente, pode descomentar a linha abaixo e colocar sua chave diretamente:\n",
    "# openai_api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"AVISO: A variável de ambiente OPENAI_API_KEY não está definida.\")\n",
    "    print(\"Por favor, defina-a ou insira sua chave diretamente no código.\")\n",
    "    # Exemplo (NÃO RECOMENDADO PARA PRODUÇÃO):\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"sk-...\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20be415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definição das Ferramentas Existentes (Mantenha as suas) ---\n",
    "def get_text_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai todo o texto visível de uma URL fornecida.\n",
    "    Útil para ler o conteúdo de páginas web.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10) # Adiciona um timeout para evitar esperas infinitas\n",
    "        response.raise_for_status()  # Lança um erro para códigos de status HTTP ruins (4xx ou 5xx)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "\n",
    "        text = soup.get_text()\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "        max_length = 4000\n",
    "        if len(text) > max_length:\n",
    "            print(f\"ATENÇÃO: Texto da URL truncado de {len(text)} para {max_length} caracteres.\")\n",
    "            text = text[:max_length] + \"...\"\n",
    "        return text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Erro ao acessar a URL: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao processar o conteúdo da URL: {e}\"\n",
    "\n",
    "url_text_extractor_tool = Tool(\n",
    "    name=\"get_text_from_url\",\n",
    "    func=get_text_from_url,\n",
    "    description=\"Útil para extrair o conteúdo de texto de uma página web a partir de uma URL. Forneça uma URL completa como entrada.\"\n",
    ")\n",
    "\n",
    "async def get_youtube_info(url_and_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Simula a extração de informações de um vídeo do YouTube usando um LLM.\n",
    "    Recebe uma string no formato 'URL_DO_VIDEO|SUA_PERGUNTA'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = url_and_query.split('|', 1)\n",
    "        if len(parts) != 2:\n",
    "            return \"Erro: Formato de entrada inválido. Use 'URL_DO_VIDEO|SUA_PERGUNTA'.\"\n",
    "\n",
    "        youtube_url = parts[0].strip()\n",
    "        user_query = parts[1].strip()\n",
    "\n",
    "        if not youtube_url or not user_query:\n",
    "            return \"Erro: URL do vídeo ou pergunta não fornecida.\"\n",
    "\n",
    "        prompt_text = f\"Dado o seguinte URL de vídeo do YouTube: {youtube_url}\\n\\nResponda à seguinte pergunta, imaginando o conteúdo do vídeo ou resumindo-o se você tiver informações contextuais sobre ele: \\\"{user_query}\\\"\\n\\nSe você não souber, diga que não sabe com base no contexto fornecido.\"\n",
    "\n",
    "        chat_history = [{ \"role\": \"user\", \"parts\": [{ \"text\": prompt_text }] }]\n",
    "        payload = { \"contents\": chat_history }\n",
    "        apiKey = \"\"\n",
    "        apiUrl = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={apiKey}\"\n",
    "\n",
    "        response = requests.post(apiUrl, headers={'Content-Type': 'application/json'}, data=json.dumps(payload))\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "\n",
    "        if result.get(\"candidates\") and len(result[\"candidates\"]) > 0 and \\\n",
    "           result[\"candidates\"][0].get(\"content\") and \\\n",
    "           result[\"candidates\"][0][\"content\"].get(\"parts\") and \\\n",
    "           len(result[\"candidates\"][0][\"content\"][\"parts\"]) > 0:\n",
    "            return result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        else:\n",
    "            return \"Não foi possível obter uma resposta do LLM para esta pergunta.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Erro ao acessar a API da OpenAI/Google Gemini: {e}. Verifique sua conexão ou quota.\"\n",
    "    except Exception as e:\n",
    "        return f\"Ocorreu um erro inesperado ao processar a requisição: {e}\"\n",
    "\n",
    "youtube_info_extractor_tool = Tool(\n",
    "    name=\"get_youtube_info\",\n",
    "    func=get_youtube_info,\n",
    "    description=\"Útil para obter informações sobre um vídeo do YouTube. A entrada deve ser no formato 'URL_DO_VIDEO|SUA_PERGUNTA', por exemplo, 'https://www.youtube.com/watch?v=dQw4w9WgXcQ|Qual é o tema principal deste vídeo?'\"\n",
    ")\n",
    "\n",
    "# --- NOVA FERRAMENTA: Monitor de Eletromagnetismo (Consulta de Capítulo por TXT) ---\n",
    "async def lookup_electromagnetism_chapter_from_txt(chapter_identifier_and_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Atua como um monitor de Eletromagnetismo, buscando informações em um capítulo específico\n",
    "    lendo o conteúdo de um arquivo TXT local e respondendo a uma pergunta com base nesse conteúdo.\n",
    "\n",
    "    A entrada deve ser uma string no formato 'IDENTIFICADOR_DO_CAPITULO|SUA_PERGUNTA'.\n",
    "    O IDENTIFICADOR_DO_CAPITULO será usado para formar o nome do arquivo (ex: 'Capitulo 2' -> 'Capitulo 2.txt').\n",
    "    Ex: 'Capitulo 2|O que é a Lei de Coulomb?'\n",
    "\n",
    "    Args:\n",
    "        chapter_identifier_and_query (str): Uma string contendo o identificador do capítulo\n",
    "                                            e a pergunta do aluno, separados por '|'.\n",
    "\n",
    "    Returns:\n",
    "        str: A resposta do LLM baseada no conteúdo do capítulo ou uma mensagem de erro.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = chapter_identifier_and_query.split('|', 1)\n",
    "        if len(parts) != 2:\n",
    "            return \"Erro: Formato de entrada inválido. Use 'IDENTIFICADOR_DO_CAPITULO|SUA_PERGUNTA'.\"\n",
    "\n",
    "        chapter_identifier = parts[0].strip()\n",
    "        student_question = parts[1].strip()\n",
    "\n",
    "        if not chapter_identifier or not student_question:\n",
    "            return \"Erro: Identificador do capítulo ou pergunta não fornecida.\"\n",
    "\n",
    "        # Constrói o nome do arquivo esperado (ex: \"Capitulo 2.txt\")\n",
    "        file_name = f\"{chapter_identifier}.txt\"\n",
    "        # Caminho completo para o arquivo (assumindo que está na mesma pasta do script)\n",
    "        # os.getcwd() retorna o diretório de trabalho atual.\n",
    "        file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            return f\"Erro: Arquivo '{file_name}' não encontrado na pasta atual. Certifique-se de que o arquivo está na mesma pasta que o script.\"\n",
    "\n",
    "        chapter_content = \"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                chapter_content = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                    chapter_content = file.read()\n",
    "            except Exception as e:\n",
    "                return f\"Erro de decodificação ao ler o arquivo '{file_name}': {e}\"\n",
    "        except Exception as e:\n",
    "            return f\"Erro ao ler o arquivo '{file_name}': {e}\"\n",
    "\n",
    "        if not chapter_content.strip():\n",
    "            return f\"Erro: O arquivo '{file_name}' está vazio ou não contém texto legível.\"\n",
    "\n",
    "        max_content_length = 25000 # Limite de tokens para o gpt-4o-mini\n",
    "        if len(chapter_content) > max_content_length:\n",
    "            chapter_content = chapter_content[:max_content_length] + \"\\n[CONTEÚDO TRUNCADO]\"\n",
    "            print(f\"Aviso: Conteúdo do capítulo '{chapter_identifier}' truncado para {max_content_length} caracteres.\")\n",
    "\n",
    "        prompt_text = (\n",
    "            f\"Você é um monitor de Eletromagnetismo. Um aluno perguntou sobre o capítulo '{chapter_identifier}'. \"\n",
    "            f\"Aqui está o conteúdo do capítulo para referência:\\n\\n\"\n",
    "            f\"```chapter_content\\n{chapter_content}\\n```\\n\\n\"\n",
    "            f\"Com base APENAS neste conteúdo do capítulo, responda à seguinte pergunta do aluno: \\\"{student_question}\\\"\\n\"\n",
    "            f\"Se a resposta não estiver explicitamente no texto fornecido, diga que a informação não está disponível no capítulo ou que você não pode responder com base nele.\"\n",
    "        )\n",
    "\n",
    "        llm_openai = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "        chat_history = [{ \"role\": \"user\", \"parts\": [{ \"text\": prompt_text }] }]\n",
    "        payload = { \"messages\": chat_history } # OpenAI API expects 'messages' not 'contents'\n",
    "\n",
    "        apiKey = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not apiKey:\n",
    "            return \"Erro: Chave da API da OpenAI não configurada. Por favor, defina a variável de ambiente OPENAI_API_KEY.\"\n",
    "\n",
    "        apiUrl = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {apiKey}'\n",
    "        }\n",
    "\n",
    "        response = requests.post(apiUrl, headers=headers, data=json.dumps(payload))\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "\n",
    "        if result.get(\"choices\") and len(result[\"choices\"]) > 0 and \\\n",
    "           result[\"choices\"][0].get(\"message\") and \\\n",
    "           result[\"choices\"][0][\"message\"].get(\"content\"):\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            return \"Não foi possível obter uma resposta do monitor para esta pergunta.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Erro ao acessar a API da OpenAI: {e}. Verifique sua conexão, quota ou chave da API.\"\n",
    "    except Exception as e:\n",
    "        return f\"Ocorreu um erro inesperado ao consultar o capítulo: {e}\"\n",
    "\n",
    "electromagnetism_monitor_tool = Tool(\n",
    "    name=\"lookup_electromagnetism_chapter\",\n",
    "    func=lookup_electromagnetism_chapter_from_txt,\n",
    "    description=(\n",
    "        \"Útil para consultar informações em um capítulo específico do material de Eletromagnetismo. \"\n",
    "        \"A entrada deve ser o IDENTIFICADOR EXATO DO CAPÍTULO (ex: 'Capitulo 2') seguido de '|' e, em seguida, a PERGUNTA do aluno. \"\n",
    "        \"O agente tentará ler o arquivo TXT correspondente (ex: 'Capitulo 2.txt') na mesma pasta do script.\"\n",
    "    )\n",
    ")\n",
    "# --- NOVA FERRAMENTA: Ler TXT Local e Criar Título ---\n",
    "async def read_txt_and_create_title(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Lê o conteúdo de um arquivo TXT localmente e cria um título curto e descritivo para ele\n",
    "    usando o modelo gpt-4o-mini.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): O caminho completo para o arquivo TXT local.\n",
    "\n",
    "    Returns:\n",
    "        str: O título gerado pelo modelo de linguagem ou uma mensagem de erro.\n",
    "    \"\"\"\n",
    "    if not file_path.strip():\n",
    "        return \"Erro: O caminho do arquivo TXT não foi fornecido.\"\n",
    "\n",
    "    # Verifica se o arquivo existe no sistema de arquivos local\n",
    "    if not os.path.exists(file_path):\n",
    "        return f\"Erro: Arquivo não encontrado no caminho: {file_path}\"\n",
    "\n",
    "    text_content = \"\"\n",
    "    try:\n",
    "        # Tenta ler com UTF-8, depois com latin-1 se houver erro de decodificação\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text_content = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                text_content = file.read()\n",
    "        except Exception as e:\n",
    "            return f\"Erro de decodificação ao ler o arquivo TXT: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao ler o arquivo TXT: {e}\"\n",
    "\n",
    "    if not text_content.strip():\n",
    "        return \"Erro: O arquivo TXT está vazio ou não contém texto legível.\"\n",
    "\n",
    "    # Limita o tamanho do texto para evitar exceder o limite de tokens do LLM\n",
    "    max_text_length = 15000  # Ajuste conforme necessário e o limite do seu LLM\n",
    "    if len(text_content) > max_text_length:\n",
    "        text_content = text_content[:max_text_length] + \"\\n[CONTEÚDO TRUNCADO PARA CABER NO LIMITE DO MODELO]\"\n",
    "        print(f\"Aviso: Conteúdo do TXT truncado para {max_text_length} caracteres para caber no prompt do LLM.\")\n",
    "\n",
    "    # Constrói o prompt para o modelo de linguagem\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Crie um título curto e descritivo para o seguinte conteúdo de texto:\\n\\n{text}\\n\\nTítulo:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Inicializa o modelo de linguagem. Usa gpt-4o-mini como solicitado.\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "        # Invoca o LLM com o prompt formatado e o conteúdo do arquivo\n",
    "        response_llm = llm.invoke(prompt_template.format(text=text_content))\n",
    "        return response_llm.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Ocorreu um erro ao gerar o título com o LLM: {e}\"\n",
    "\n",
    "# Criação da Ferramenta LangChain para ler TXT local\n",
    "create_title_from_local_txt_tool = Tool(\n",
    "    name=\"create_title_from_local_txt\",\n",
    "    func=read_txt_and_create_title,\n",
    "    description=(\n",
    "        \"Útil para ler um arquivo TXT localmente e criar um título curto e descritivo para o seu conteúdo. \"\n",
    "        \"A entrada deve ser o CAMINHO COMPLETO para o arquivo TXT no sistema de arquivos local. \"\n",
    "        \"Ex: 'C:/Users/SeuUsuario/Documentos/meu_texto.txt' ou '/home/usuario/documentos/meu_texto.txt'\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def extract_text_from_pdf_sync(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai todo o texto de um arquivo PDF localmente (função síncrona).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        return f\"Erro: Arquivo PDF não encontrado no caminho: {pdf_path}\"\n",
    "\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao ler o PDF: {e}\"\n",
    "\n",
    "extract_text_from_pdf_tool = Tool(\n",
    "    name=\"extract_text_from_pdf\",\n",
    "    func=extract_text_from_pdf_sync, # Agora chama a função síncrona\n",
    "    description=\"Útil para extrair todo o texto de um arquivo PDF local. A entrada deve ser o CAMINHO COMPLETO para o arquivo PDF.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038403e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Inicialização do Modelo de Linguagem (LLM) ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7) # Modelo gpt-4o-mini como solicitado\n",
    "\n",
    "# --- 4. Preparação do Agente ---\n",
    "tools = [\n",
    "    url_text_extractor_tool,\n",
    "    youtube_info_extractor_tool,\n",
    "    extract_text_from_pdf_tool,\n",
    "    create_title_from_local_txt_tool,\n",
    "    electromagnetism_monitor_tool\n",
    "]\n",
    "\n",
    "custom_prompt_template = \"\"\"\n",
    "Você é um assistente de IA útil e inteligente.\n",
    "Seu nome é James Moriarty.\n",
    "Sua principal função é responder às perguntas do usuário.\n",
    "PRIMEIRO, tente responder diretamente usando seu próprio conhecimento.\n",
    "SEGUNDO, se você não souber a resposta, ou se a pergunta exigir informações muito específicas, atualizadas, ou a análise de um documento/URL, então use as ferramentas disponíveis.\n",
    "Use as ferramentas APENAS quando for estritamente necessário para obter informações que você não possui.\n",
    "\n",
    "Aqui estão as ferramentas que você pode usar:\n",
    "{tools}\n",
    "\n",
    "Use o seguinte formato:\n",
    "\n",
    "Question: a pergunta de entrada que você deve responder\n",
    "Thought: você deve sempre pensar sobre o que fazer.\n",
    "Action: a ação a ser tomada, deve ser uma das [{tool_names}]\n",
    "Action Input: a entrada para a ação (NÃO use aspas duplas aqui)\n",
    "Observation: o resultado da ação\n",
    "... (este Thought/Action/Action Input/Observation pode se repetir N vezes)\n",
    "Thought: Eu sei a resposta final\n",
    "Final Answer: a resposta final à pergunta original\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(custom_prompt_template)\n",
    "prompt = prompt.partial(\n",
    "    tools=str(tools),\n",
    "    tool_names=\", \".join([tool.name for tool in tools])\n",
    ")\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e53b347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop de eventos já rodando. Agendando tarefa...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Agente Moriarty - Monitor de Eletromagnetismo ---\n",
      "Para sair, digite 'sair'.\n",
      "Exemplos de perguntas:\n",
      " - 'O que é a Lei de Coulomb no Capitulo 2?'\n",
      " - 'Resuma o Capitulo 1.'\n",
      " - 'Qual é a definição de potencial elétrico no Capitulo 3?'\n",
      " - 'Obrigado.'\n",
      "\n",
      "Sua pergunta (ou 'sair' para terminar): "
     ]
    }
   ],
   "source": [
    "# --- 5. Execução do Agente (Loop de Chat Assíncrono para Jupyter) ---\n",
    "\n",
    "async def main_chat_loop():\n",
    "    print(\"\\n--- Agente Moriarty - Monitor de Eletromagnetismo ---\")\n",
    "    print(\"Para sair, digite 'sair'.\")\n",
    "    print(\"Exemplos de perguntas:\")\n",
    "    print(\" - 'O que é a Lei de Coulomb no Capitulo 2?'\")\n",
    "    print(\" - 'Resuma o Capitulo 1.'\")\n",
    "    print(\" - 'Qual é a definição de potencial elétrico no Capitulo 3?'\")\n",
    "    print(\" - 'Obrigado.'\") # Para testar resposta direta\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = await asyncio.to_thread(input, \"\\nSua pergunta (ou 'sair' para terminar): \")\n",
    "            if user_input.lower() == 'sair':\n",
    "                break\n",
    "\n",
    "            print(f\"\\nVocê: {user_input}\")\n",
    "            print(\"Moriarty pensando...\")\n",
    "            response = await agent_executor.ainvoke({\"input\": user_input})\n",
    "            print(\"\\n--- Resposta do Agente ---\")\n",
    "            print('Moriarty:', response[\"output\"])\n",
    "        except Exception as e:\n",
    "            print(f\"\\nOcorreu um erro: {e}\")\n",
    "            print(\"Tente novamente ou verifique se sua chave da OpenAI está configurada corretamente.\")\n",
    "\n",
    "    print(\"\\nAgente encerrado.\")\n",
    "\n",
    "# Para executar em Jupyter Notebooks, é melhor agendar a tarefa\n",
    "# em vez de usar asyncio.run() diretamente na célula principal,\n",
    "# pois asyncio.run() pode bloquear o kernel.\n",
    "# Apenas execute esta linha UMA VEZ. Se você reexecutar a célula,\n",
    "# pode precisar reiniciar o kernel do Jupyter.\n",
    "if __name__ == \"__main__\":\n",
    "    # Verifica se já existe um loop de eventos rodando\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:\n",
    "        loop = None\n",
    "\n",
    "    if loop and loop.is_running():\n",
    "        # Se um loop já estiver rodando (ex: em um notebook Jupyter),\n",
    "        # agende a tarefa para ser executada no loop existente.\n",
    "        print(\"Loop de eventos já rodando. Agendando tarefa...\")\n",
    "        loop.create_task(main_chat_loop())\n",
    "    else:\n",
    "        # Se nenhum loop estiver rodando (ex: script python normal),\n",
    "        # inicie um novo loop e execute a função.\n",
    "        print(\"Iniciando novo loop de eventos...\")\n",
    "        asyncio.run(main_chat_loop())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
